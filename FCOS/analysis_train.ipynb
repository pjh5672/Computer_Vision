{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "db49a882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO=====>voc dataset init finished  ! !\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from VOC_dataset import VOCDataset\n",
    "from config import DefaultConfig\n",
    "from fcos import FCOS\n",
    "from loss import GenTargets, LOSS\n",
    "\n",
    "train_dataset=VOCDataset(\"f:/Dataset/VOC/VOC2007/\",resize_size=[512,800],split='train')\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=1,shuffle=True,collate_fn=train_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b36c1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DefaultConfig\n",
    "fcos_body = FCOS(config)\n",
    "target_layer=GenTargets(strides=config.strides,limit_range=config.limit_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "555039b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_step, data in enumerate(train_loader):\n",
    "    batch_imgs, batch_boxes, batch_classes = data\n",
    "    \n",
    "    out = fcos_body(batch_imgs)\n",
    "    targets=target_layer([out,batch_boxes,batch_classes])\n",
    "    \n",
    "    if epoch_step == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de819a",
   "metadata": {},
   "source": [
    "### GenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "02eadb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 16, 32, 64, 128] [[-1, 64], [64, 128], [128, 256], [256, 512], [512, 999999]]\n"
     ]
    }
   ],
   "source": [
    "strides = config.strides\n",
    "limit_ranges = config.limit_range\n",
    "\n",
    "print(strides, limit_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e50ae655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls_logits  list contains five [batch_size,class_num,h,w]  \n",
    "# cnt_logits  list contains five [batch_size,1,h,w]  \n",
    "# reg_preds   list contains five [batch_size,4,h,w]  \n",
    "# gt_boxes [batch_size,m,4]  FloatTensor  \n",
    "# classes [batch_size,m]  LongTensor\n",
    "cls_logits, cnt_logits, reg_preds = out\n",
    "gt_boxes = batch_boxes\n",
    "classes = batch_classes\n",
    "\n",
    "cls_targets_all_level = []\n",
    "cnt_targets_all_level = []\n",
    "reg_targets_all_level = []\n",
    "\n",
    "level = 0\n",
    "level_out = [cls_logits[level], cnt_logits[level], reg_preds[level]]\n",
    "# for level in range(len(cls_logits)):\n",
    "#     level_out = [cls_logits[level], cnt_logits[level], reg_preds[level]]\n",
    "#     level_targets = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4f7c299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ._gen_level_targets(level_out,gt_boxes,classes,self.strides[level], self.limit_range[level])\n",
    "stride = strides[level]\n",
    "limit_range = limit_ranges[level]\n",
    "sample_radiu_ratio = 1.5\n",
    "\n",
    "cls_logits, cnt_logits, reg_preds = level_out\n",
    "batch_size=cls_logits.shape[0]\n",
    "class_num = cls_logits.shape[1]\n",
    "m = gt_boxes.shape[1]\n",
    "\n",
    "cls_logits = cls_logits.permute(0, 2, 3, 1) #[batch_size,h,w,class_num]  \n",
    "coords=coords_fmap2orig(cls_logits,stride)\n",
    "cls_logits=cls_logits.reshape((batch_size,-1,class_num)) #[batch_size,h*w,class_num]  \n",
    "\n",
    "cnt_logits=cnt_logits.permute(0,2,3,1)\n",
    "cnt_logits=cnt_logits.reshape((batch_size,-1,1))\n",
    "\n",
    "reg_preds=reg_preds.permute(0,2,3,1)\n",
    "reg_preds=reg_preds.reshape((batch_size,-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "68709a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mul_w=cls_logits.shape[1]\n",
    "\n",
    "x=coords[:,0]\n",
    "y=coords[:,1]\n",
    "\n",
    "l_off = x[None, :, None] - gt_boxes[...,0][:, None, :] # x_min\n",
    "t_off = y[None,:,None] - gt_boxes[...,1][:,None,:] # y_min\n",
    "r_off = gt_boxes[...,2][:,None,:] - x[None,:,None] # x_max\n",
    "b_off = gt_boxes[...,3][:,None,:] - y[None,:,None] # y_max\n",
    "\n",
    "ltrb_off = torch.stack([l_off, t_off, r_off, b_off],dim=-1) # [batch_size,h*w,m,4]\n",
    "areas = (ltrb_off[...,0] + ltrb_off[...,2]) * (ltrb_off[...,1] + ltrb_off[...,3]) # [batch_size,h*w,m]\n",
    "\n",
    "off_min = torch.min(ltrb_off, dim=-1)[0] # [batch_size,h*w,m]\n",
    "off_max = torch.max(ltrb_off,dim=-1)[0] # [batch_size,h*w,m]\n",
    "\n",
    "mask_in_gtboxes = off_min > 0\n",
    "mask_in_level = (off_max > limit_range[0])&(off_max<=limit_range[1])\n",
    "\n",
    "radiu = stride*sample_radiu_ratio\n",
    "gt_center_x = (gt_boxes[...,0]+gt_boxes[...,2])/2\n",
    "gt_center_y = (gt_boxes[...,1]+gt_boxes[...,3])/2\n",
    "\n",
    "c_l_off = x[None,:,None] - gt_center_x[:,None,:]\n",
    "c_t_off = y[None,:,None] - gt_center_y[:,None,:]\n",
    "c_r_off = gt_center_x[:,None,:] - x[None,:,None]\n",
    "c_b_off = gt_center_y[:,None,:] - y[None,:,None]\n",
    "\n",
    "c_ltrb_off = torch.stack([c_l_off, c_t_off, c_r_off, c_b_off], dim=-1)\n",
    "c_off_max = torch.max(c_ltrb_off,dim=-1)[0]\n",
    "\n",
    "mask_center = c_off_max < radiu\n",
    "mask_pos = mask_in_gtboxes & mask_in_level & mask_center\n",
    "\n",
    "areas[~mask_pos]=99999999 # make negative\n",
    "areas_min_ind = torch.min(areas, dim=-1)[1]\n",
    "\n",
    "reg_targets=ltrb_off[torch.zeros_like(areas,dtype=torch.bool).scatter_(-1,areas_min_ind.unsqueeze(dim=-1),1)]\n",
    "reg_targets=torch.reshape(reg_targets,(batch_size,-1,4))\n",
    "\n",
    "classes = torch.broadcast_tensors(classes[:,None,:], areas.long())[0]\n",
    "cls_targets=classes[torch.zeros_like(areas,dtype=torch.bool).scatter_(-1,areas_min_ind.unsqueeze(dim=-1),1)]\n",
    "cls_targets=torch.reshape(cls_targets,(batch_size,-1,1))\n",
    "\n",
    "left_right_min = torch.min(reg_targets[..., 0], reg_targets[..., 2])\n",
    "left_right_max = torch.max(reg_targets[..., 0], reg_targets[..., 2])\n",
    "top_bottom_min = torch.min(reg_targets[..., 1], reg_targets[..., 3])\n",
    "top_bottom_max = torch.max(reg_targets[..., 1], reg_targets[..., 3])\n",
    "\n",
    "cnt_targets=((left_right_min*top_bottom_min)/(left_right_max*top_bottom_max+1e-10)).sqrt().unsqueeze(dim=-1)\n",
    "\n",
    "mask_pos_2 = mask_pos.long().sum(dim=-1)\n",
    "mask_pos_2 = mask_pos_2>=1\n",
    "\n",
    "cls_targets[~mask_pos_2]=0\n",
    "cnt_targets[~mask_pos_2]=-1\n",
    "reg_targets[~mask_pos_2]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45e81d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords=coords_fmap2orig(cls_logits,stride).to(device=gt_boxes.device)#[h*w,2]\n",
    "h,w=cls_logits.shape[1:3]\n",
    "stride = strides[level]\n",
    "shifts_x = torch.arange(0, w*stride, stride, dtype=torch.float32)\n",
    "shifts_y = torch.arange(0, h*stride, stride, dtype=torch.float32)\n",
    "\n",
    "shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "shift_x = torch.reshape(shift_x, [-1])\n",
    "shift_y = torch.reshape(shift_y, [-1])\n",
    "\n",
    "coords = torch.stack([shift_x, shift_y], -1) + stride // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b87307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_fmap2orig(feature,stride):\n",
    "    h,w=feature.shape[1:3]\n",
    "    shifts_x = torch.arange(0, w * stride, stride, dtype=torch.float32)\n",
    "    shifts_y = torch.arange(0, h * stride, stride, dtype=torch.float32)\n",
    "\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "    shift_x = torch.reshape(shift_x, [-1])\n",
    "    shift_y = torch.reshape(shift_y, [-1])\n",
    "    coords = torch.stack([shift_x, shift_y], -1) + stride // 2\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfc436",
   "metadata": {},
   "source": [
    "### LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8678104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_logits, cnt_logits, reg_preds = out\n",
    "cls_targets, cnt_targets, reg_targets = targets\n",
    "\n",
    "mask_pos = (cnt_targets>-1).squeeze(dim=-1)\n",
    "cls_loss=compute_cls_loss(cls_logits,cls_targets,mask_pos).mean()\n",
    "cnt_loss=compute_cnt_loss(cnt_logits,cnt_targets,mask_pos).mean()\n",
    "reg_loss=compute_reg_loss(reg_preds,reg_targets,mask_pos, mode='iou').mean()\n",
    "\n",
    "total_loss=cls_loss+cnt_loss+reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7f78abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.0966, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "86a42b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_cls_loss(preds,targets,mask)\n",
    "batch_size=cls_targets.shape[0]\n",
    "class_num=cls_logits[0].shape[1]\n",
    "preds_reshape=[]\n",
    "\n",
    "mask = mask_pos.unsqueeze(dim=-1)\n",
    "num_pos = torch.sum(mask,dim=[1,2]).clamp_(min=1).float()\n",
    "\n",
    "for cls_logit in cls_logits:\n",
    "    cls_logit = cls_logit.permute(0,2,3,1)\n",
    "    cls_logit = torch.reshape(cls_logit, [batch_size,-1,class_num])\n",
    "    preds_reshape.append(cls_logit)\n",
    "    \n",
    "cls_preds = torch.cat(preds_reshape,dim=1)\n",
    "\n",
    "loss=[]\n",
    "for batch_index in range(batch_size):\n",
    "    pred_pos=cls_preds[batch_index]#[sum(_h*_w),class_num]\n",
    "    target_pos=cls_targets[batch_index]#[sum(_h*_w),1]\n",
    "    target_pos=(torch.arange(1,class_num+1)[None,:]==target_pos).float()#sparse-->onehot\n",
    "    loss.append(focal_loss_from_logits(pred_pos,target_pos).view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ea36d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cls_loss(preds,targets,mask):\n",
    "    batch_size=targets.shape[0]\n",
    "    preds_reshape=[]\n",
    "    class_num=preds[0].shape[1]\n",
    "    mask=mask.unsqueeze(dim=-1)\n",
    "    # mask=targets>-1#[batch_size,sum(_h*_w),1]\n",
    "    num_pos=torch.sum(mask,dim=[1,2]).clamp_(min=1).float()#[batch_size,]\n",
    "    for pred in preds:\n",
    "        pred=pred.permute(0,2,3,1)\n",
    "        pred=torch.reshape(pred,[batch_size,-1,class_num])\n",
    "        preds_reshape.append(pred)\n",
    "    preds=torch.cat(preds_reshape,dim=1)#[batch_size,sum(_h*_w),class_num]\n",
    "    assert preds.shape[:2]==targets.shape[:2]\n",
    "    loss=[]\n",
    "    for batch_index in range(batch_size):\n",
    "        pred_pos=preds[batch_index]#[sum(_h*_w),class_num]\n",
    "        target_pos=targets[batch_index]#[sum(_h*_w),1]\n",
    "        target_pos=(torch.arange(1,class_num+1,device=target_pos.device)[None,:]==target_pos).float()#sparse-->onehot\n",
    "        loss.append(focal_loss_from_logits(pred_pos,target_pos).view(1))\n",
    "    return torch.cat(loss,dim=0)/num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e6931577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reg_loss(preds,targets,mask,mode='giou'):\n",
    "    batch_size=targets.shape[0]\n",
    "    c=targets.shape[-1]\n",
    "    preds_reshape=[]\n",
    "    # mask=targets>-1#[batch_size,sum(_h*_w),4]\n",
    "    num_pos=torch.sum(mask,dim=1).clamp_(min=1).float()#[batch_size,]\n",
    "    for pred in preds:\n",
    "        pred=pred.permute(0,2,3,1)\n",
    "        pred=torch.reshape(pred,[batch_size,-1,c])\n",
    "        preds_reshape.append(pred)\n",
    "    preds=torch.cat(preds_reshape,dim=1)\n",
    "    assert preds.shape==targets.shape#[batch_size,sum(_h*_w),4]\n",
    "    loss=[]\n",
    "    for batch_index in range(batch_size):\n",
    "        pred_pos=preds[batch_index][mask[batch_index]]#[num_pos_b,4]\n",
    "        target_pos=targets[batch_index][mask[batch_index]]#[num_pos_b,4]\n",
    "        assert len(pred_pos.shape)==2\n",
    "        if mode=='iou':\n",
    "            loss.append(iou_loss(pred_pos,target_pos).view(1))\n",
    "        elif mode=='giou':\n",
    "            loss.append(giou_loss(pred_pos,target_pos).view(1))\n",
    "        else:\n",
    "            raise NotImplementedError(\"reg loss only implemented ['iou','giou']\")\n",
    "    return torch.cat(loss,dim=0)/num_pos#[batch_size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8fb5b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cnt_loss(preds,targets,mask):\n",
    "    batch_size=targets.shape[0]\n",
    "    c=targets.shape[-1]\n",
    "    preds_reshape=[]\n",
    "    mask=mask.unsqueeze(dim=-1)\n",
    "    # mask=targets>-1#[batch_size,sum(_h*_w),1]\n",
    "    num_pos=torch.sum(mask,dim=[1,2]).clamp_(min=1).float()#[batch_size,]\n",
    "    for pred in preds:\n",
    "        pred=pred.permute(0,2,3,1)\n",
    "        pred=torch.reshape(pred,[batch_size,-1,c])\n",
    "        preds_reshape.append(pred)\n",
    "    preds=torch.cat(preds_reshape,dim=1)\n",
    "    assert preds.shape==targets.shape#[batch_size,sum(_h*_w),1]\n",
    "    loss=[]\n",
    "    for batch_index in range(batch_size):\n",
    "        pred_pos=preds[batch_index][mask[batch_index]]#[num_pos_b,]\n",
    "        target_pos=targets[batch_index][mask[batch_index]]#[num_pos_b,]\n",
    "        assert len(pred_pos.shape)==1\n",
    "        loss.append(nn.functional.binary_cross_entropy_with_logits(input=pred_pos,target=target_pos,reduction='sum').view(1))\n",
    "    return torch.cat(loss,dim=0)/num_pos#[batch_size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1f8988af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_from_logits(preds,targets,gamma=2.0,alpha=0.25):\n",
    "    preds=preds.sigmoid()\n",
    "    pt=preds*targets+(1.0-preds)*(1.0-targets)\n",
    "    w=alpha*(1.0-targets)+(1.0-alpha)*targets\n",
    "    loss=-w*torch.pow((1.0-pt),gamma)*pt.log()\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "695e93c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_loss(preds,targets):\n",
    "    lt=torch.min(preds[:,:2],targets[:,:2])\n",
    "    rb=torch.min(preds[:,2:],targets[:,2:])\n",
    "    wh=(rb+lt).clamp(min=0)\n",
    "    overlap=wh[:,0]*wh[:,1]#[n]\n",
    "    area1=(preds[:,2]+preds[:,0])*(preds[:,3]+preds[:,1])\n",
    "    area2=(targets[:,2]+targets[:,0])*(targets[:,3]+targets[:,1])\n",
    "    iou=overlap/(area1+area2-overlap)\n",
    "    loss=-iou.clamp(min=1e-6).log()\n",
    "    return loss.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "0893a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_index = 0\n",
    "pred_pos=cls_preds[batch_index]\n",
    "target_pos=cls_targets[batch_index]\n",
    "target_pos=(torch.arange(1,class_num+1)[None,:]==target_pos).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "58cd2627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "928c88a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7983, 80])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b123602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
